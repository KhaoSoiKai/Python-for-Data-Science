{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression from Scratch\n",
    "\n",
    "| | Egg price  | Gold price    | Oil price   | GDP   |\n",
    "|---:|:-------------|:-----------|:------|:------|\n",
    "| 1 | 3  | 100       | 4   | 21   |\n",
    "| 2 | 4  | 500    | 7   | 43     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#sample 1  $x^1$\n",
    "x1 = np.array([3, 100, 4])\n",
    "y1 = np.array([21])\n",
    "\n",
    "#what's the idea of prediction?  What is machine learning?\n",
    "#- find the weights that can bring you from x1 to y1\n",
    "\n",
    "#first sample\n",
    "#3 * w1 + 100 * w2 + 4 * w3 = 21\n",
    "#3 * 1  + 100 * 1  + 4 * 1  = 107\n",
    "#3 * 7  + 100 * 1  + 4 * -25  = 21\n",
    "\n",
    "#machine learning is trying to find the `best` weights\n",
    "\n",
    "#2nd sample\n",
    "#4 * w1 + 500 * w2 + 7 * w3   = 43\n",
    "#4 * 7  + 500 * 1  + 7 * -25  = 353 \n",
    "\n",
    "#machine learning is trying to find the `best` weights ACROSS all samples....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([  [3, 100, 4] , [4, 500, 7]  ])\n",
    "X.shape  #(2, 3) means 2 samples = m, 3 features = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights = theta = params\n",
    "theta = np.array([7, 1, -25])\n",
    "theta.shape  #weights must be the sample shape as X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21, 353])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.dot(theta)\n",
    "#to be able to dot, the number should be same in the close pair\n",
    "#(2, 3)  @ (3, ) = (2, )\n",
    "#(4, 6)  @ (6, 1) = (4, 1)\n",
    "#(4, 6, 1) @ (1, 2) = (4, 6, 1, 2)\n",
    "X @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0] * theta[0] + X[0][1] * theta[1] + X[0][2] * theta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of terms and notations\n",
    "\n",
    "#2 samples\n",
    "#3 features - egg price, gold price, oil price\n",
    "    #features are the variables used for predicting the label\n",
    "    #factors, independent variables, predictors, X\n",
    "\n",
    "#egg price - x_1 --> always a vector,  e.g., [3, 4]\n",
    "#gold price - x_2 --> always a vector, e.g., [100, 500]\n",
    "#oil price - x_3 --> always a vector, e.g., [4, 7]\n",
    "#we call egg price + gold price + oil price - whole `feature matrix` --> \\mathbf{X}\n",
    "    \n",
    "#1 label - gdp\n",
    "    #label is the variable that we want to predict....\n",
    "    #target, outcome, y\n",
    "    #y_1 = y = a vector of labels, e.g., [21, 43]\n",
    "    \n",
    "#Tips: small and big\n",
    "# small mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math notations:\n",
    "\n",
    "- normal a -> scalar (one number)\n",
    "- bold  $\\mathbf{a}$  --> vector (a 1D numpy array)\n",
    "- bold  $\\mathbf{A}$  --> matrix (a 2D numpy array....)\n",
    "\n",
    "- $\\mathbf{x}_1^2$  --> feature 1, second sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the best weight?\n",
    "\n",
    "- There are many ways, e.g., closed form, gradient descent, expectation\n",
    "- gradient descent / backpropagation\n",
    "  - You adjust the weight slightly, based on the errors....\n",
    "  - How to adjust based on the errors\n",
    "\n",
    "1. We need to find out how to measure errors\n",
    "\n",
    "2. We need to know how much to adjust the error\n",
    "\n",
    "3. We need to change the weight accordingly\n",
    "\n",
    "4. Run predict again....\n",
    "\n",
    "5. We stop when our errors are decreased no more....or reach some max iterations..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
