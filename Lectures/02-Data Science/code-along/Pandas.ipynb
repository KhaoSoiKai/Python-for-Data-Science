{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Pandas\n",
    "\n",
    "### Readings: \n",
    "- [VANDER] Ch3\n",
    "- https://pandas.pydata.org/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is built on top of NumPy\n",
    "#   it means that Pandas, in a very raw level, is actually nothing but NumPy array\n",
    "#   pandas has added functionality, like dealing with missing values, for example\n",
    "\n",
    "# so why NumPy?  Why not use Pandas always?\n",
    "# Pandas is MUCH slower than NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract-Transform-Load (ETL) \n",
    "\n",
    "- Challenge: many data sources; maintain a lot of connectors; transform them to one single format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the name of data that pandas called, is \"Dataframe\"\n",
    "df = pd.read_csv(\"howlongwelive.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>...</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>Developing</td>\n",
       "      <td>65.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.5</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.2</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
       "0  Afghanistan  2015  Developing              65.0            263.0   \n",
       "1  Afghanistan  2014  Developing              59.9            271.0   \n",
       "2  Afghanistan  2013  Developing              59.9            268.0   \n",
       "3  Afghanistan  2012  Developing              59.5            272.0   \n",
       "4  Afghanistan  2011  Developing              59.2            275.0   \n",
       "\n",
       "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
       "0             62     0.01               71.279624         65.0      1154  ...   \n",
       "1             64     0.01               73.523582         62.0       492  ...   \n",
       "2             66     0.01               73.219243         64.0       430  ...   \n",
       "3             69     0.01               78.184215         67.0      2787  ...   \n",
       "4             71     0.01                7.097109         68.0      3013  ...   \n",
       "\n",
       "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
       "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
       "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
       "2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n",
       "3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n",
       "4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n",
       "\n",
       "    thinness  1-19 years   thinness 5-9 years  \\\n",
       "0                   17.2                 17.3   \n",
       "1                   17.5                 17.5   \n",
       "2                   17.7                 17.7   \n",
       "3                   17.9                 18.0   \n",
       "4                   18.2                 18.2   \n",
       "\n",
       "   Income composition of resources  Schooling  \n",
       "0                            0.479       10.1  \n",
       "1                            0.476       10.0  \n",
       "2                            0.470        9.9  \n",
       "3                            0.463        9.8  \n",
       "4                            0.454        9.5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you use df.head()\n",
    "#format: df.head(number of rows; default is 5; you can also put negative numbers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2938, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as I say, Pandas IS NumPy\n",
    "df.shape\n",
    "\n",
    "#means that there are 2938 rows, and 22 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality',\n",
       "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
       "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
       "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
       "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
       "       'Income composition of resources', 'Schooling'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maybe you want a list of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)\n",
    "- looking at the distribution of data\n",
    "- plot something useful\n",
    "- understand the data\n",
    "- know which features to use\n",
    "  \n",
    "Note: **this is the MOST important step in all data science**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## related seaborn\n",
    "#df.info()\n",
    "\n",
    "#list the datatypes of the dataframe\n",
    "#key: we DON'T LIKE \"object\" ==> \"string\"\n",
    "\n",
    "#so when you \"object\", you change it to numbers or drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Developing\n",
       "1       Developing\n",
       "2       Developing\n",
       "3       Developing\n",
       "4       Developing\n",
       "           ...    \n",
       "2933    Developing\n",
       "2934    Developing\n",
       "2935    Developing\n",
       "2936    Developing\n",
       "2937    Developing\n",
       "Name: Status, Length: 2938, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#two ways to access each column\n",
    "#format1:  df['colname']\n",
    "#format2:  df.colname\n",
    "df['Status']  #try df.Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Developing', 'Developed'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "developing_cond = df['Status'] == 'Developing'\n",
    "developed_cond  = df['Status'] == 'Developed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of developing countries: \", \n",
    "      len(df.Status[developing_cond]))\n",
    "\n",
    "print (\"Number of developed countries: \", \n",
    "       df.Status[developed_cond].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Status[developed_cond].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Alcohol'].max()  #try min(), mean(), median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Alcohol.min(), df.Alcohol.mean(), df.Alcohol.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise: get the rows with alcohol more than the median\n",
    "#and count\n",
    "#challenge: list these unique countries\n",
    "\n",
    "#Answer:\n",
    "#fancy_indexes = df.Alcohol > df.Alcohol.median()\n",
    "#df.Country[fancy_indexes].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise2: get the list of country\n",
    "#with Schooling more than the median\n",
    "#and GDP more than the median\n",
    "\n",
    "cond1 = df.Schooling > df.Schooling.median()\n",
    "cond2 = df.GDP > df.GDP.median()\n",
    "\n",
    "countries = df.Country[cond1 & cond2].unique()\n",
    "#use | for or\n",
    "\n",
    "type(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for any columns of continuous value, \n",
    "# it gives you count, mean, std, min, etc.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use some easy library for visualization\n",
    "#it accepts input as dataframe\n",
    "import seaborn as sns\n",
    "#seaborn: super easy library for visualization\n",
    "#it's built on top of matplotlib \n",
    "#matplotlib is the classic python library for visualization\n",
    "\n",
    "#if i want to predict egg price, using gold and oil prices\n",
    "#we called gold and oil prices MANY names\n",
    "#   features, factors, independent variables, predictors, X\n",
    "#   here, gold is called x_1, oil is called x_2\n",
    "#we called egg price MANY names\n",
    "#   labels, targets, outcomes, dependent variables, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. countplot is to plot the discrete x_1 or y\n",
    "sns.countplot(data = df, x=\"Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. distplot or displt is to plot the continuous x_1 or y\n",
    "sns.displot(df.Alcohol)  #==> you get error, this is because your version is not >0.10\n",
    "#displot = distribution plot\n",
    "\n",
    "#exercise: try displot for another continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "format: .rename(\n",
    "    columns =\n",
    "    {oldname: newname,\n",
    "     oldname2: newname2,\n",
    "     oldname3: newname3}\n",
    ")\n",
    "'''\n",
    "df = df.rename(\n",
    "    columns = {'Life expectancy ': 'life-exp',\n",
    "               'Income composition of resources' : 'income',\n",
    "               'Schooling' : 'schooling'}\n",
    ")\n",
    "\n",
    "# df.head()\n",
    "\n",
    "#tips:  if you don't want to do df=, just put a argument inplace=True\n",
    "#exercise: can you change \n",
    "#   Income composition of resources to income, \n",
    "#   Schooling to schooling and \n",
    "#   Status to status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Year', 'Status', 'life-exp', 'Adult Mortality',\n",
       "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
       "       'Measles', 'BMI', 'under-five deaths', 'Polio', 'Total expenditure',\n",
       "       'Diphtheria', 'HIV/AIDS', 'GDP', 'Population', 'thinness  1-19 years',\n",
       "       'thinness 5-9 years', 'income', 'schooling'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#challenge: help clear all the spaces in the columns\n",
    "import numpy as np\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. boxplot is to plot discrete x_1 vs. continuous x_2/y\n",
    "sns.boxplot(x = df['Status'], y = df['life-exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. scatterplot is to plot continuous x_1 vs. continuous x_2/y\n",
    "#hue MUST be a discrete variable\n",
    "sns.scatterplot(x = df['Alcohol'], y = df['life-exp'], hue = df['Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Year', 'Status', 'life-exp', 'Adult Mortality',\n",
       "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
       "       'Measles', 'BMI', 'under-five deaths', 'Polio', 'Total expenditure',\n",
       "       'Diphtheria', 'HIV/AIDS', 'GDP', 'Population', 'thinness  1-19 years',\n",
       "       'thinness 5-9 years', 'income', 'schooling'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "cols = np.array(cols)\n",
    "\n",
    "type(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then i have to check how to remove\n",
    "cols = np.delete(cols, np.where(cols=='Status'))\n",
    "cols = np.delete(cols, np.where(cols=='Country'))\n",
    "cols = np.delete(cols, np.where(cols=='life-exp'))\n",
    "cols = np.delete(cols, np.where(cols=='Year'))\n",
    "\n",
    "cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise, find me the features that have very strong correlation with life-exp\n",
    "#exercise, which features have almost NO relationship with life exp\n",
    "\n",
    "#get some columns, but I also have to drop some columns - drop Status, drop Country, drop life-exp\n",
    "# import matplotlib.pyplot as plt\n",
    "# for each_col in cols: \n",
    "#     sns.scatterplot(x = df[each_col], y = df['life-exp'], hue = df['Status'])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise:  try sns.heatmap(df.corr(), annot=True)\n",
    "#df.corr() calculates the correlation between continuous features\n",
    "\n",
    "#exercise:  try to figure out how to increase the size of the figure \n",
    "# (hint: you have to change using matplotlib figure size)\n",
    "\n",
    "#1st way: use sns.set \n",
    "#2nd way: set the figure size via the plt variable of matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing / Cleaning\n",
    "\n",
    "#### 3.1 dealing with missing values\n",
    "  - Case 1: **Continuous values**\n",
    "    - Replace with:\n",
    "      - 1. **mean/median** if the distribution is normal\n",
    "      - 2. **median** if the distribution is NOT normal\n",
    "      - 3. **0** if 0 is a very common occurrence in the real-world\n",
    "      - 4. **regression** if your data fits nicely with regression, especially linear regression\n",
    "    - Do we ever drop?\n",
    "      - Almost never.  Drop columns lose a lot of values, dropping rows also lost other features....\n",
    "      - If you are super sure this is human mistake, you can drop\n",
    "  - Case 2: **Discrete values**\n",
    "    - Replace with: \n",
    "      - 1. **Majority** - when majority is like 90%\n",
    "      - 2. **No category** - when we are not so sure\n",
    "      - 3. **Ratio** - preserve the shape of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country                     0\n",
       "Year                        0\n",
       "Status                      0\n",
       "life-exp                   10\n",
       "Adult Mortality            10\n",
       "infant deaths               0\n",
       "Alcohol                   194\n",
       "percentage expenditure      0\n",
       "Hepatitis B               553\n",
       "Measles                     0\n",
       "BMI                        34\n",
       "under-five deaths           0\n",
       "Polio                      19\n",
       "Total expenditure         226\n",
       "Diphtheria                 19\n",
       "HIV/AIDS                    0\n",
       "GDP                       448\n",
       "Population                652\n",
       "thinness  1-19 years       34\n",
       "thinness 5-9 years         34\n",
       "income                    167\n",
       "schooling                 163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to quickly check missing values\n",
    "df.isna().sum()\n",
    "\n",
    "# df['life-exp'].isna().sum()\n",
    "\n",
    "#this is my plan:\n",
    "\n",
    "#features: income, schooling, status\n",
    "#label   : life-exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#typical steps to fill in missing value (continuous values)\n",
    "\n",
    "#1. Ex1: plot the distribution (income, schooling, life-exp)\n",
    "#if your data is discrete, use countplot\n",
    "sns.displot(df['income'])\n",
    "\n",
    "#2. Ex2: print mean and median\n",
    "df['income'].mean(), df['income'].median()\n",
    "\n",
    "#3. judge by yourself mean or median better, then fillna\n",
    "##########I COMMENT DUE TO POSSIBLE DATA LEAKAGE\n",
    "# df['income'] = df['income'].fillna(df['income'].median())\n",
    "#df['income'].fillna(df['income'].median(), inplace=True)  ==> you don't have assign a variable to take the value\n",
    "\n",
    "#exercise: please fillna for schooling and life-exp\n",
    "\n",
    "#1. plot the distribution\n",
    "# let's assume i plot already, and i found that median is a good representation\n",
    "# good representation - high probability\n",
    "# ##########I COMMENT DUE TO POSSIBLE DATA LEAKAGE\n",
    "# df['life-exp'] = df['life-exp'].fillna(df['life-exp'].median())\n",
    "# df['schooling'] = df['schooling'].fillna(df['schooling'].median())\n",
    "\n",
    "#make sure schooling.isna().sum() and life-exp.isna().sum() is 0\n",
    "\n",
    "#1, 2, 3, 3, 100\n",
    "\n",
    "#assert df['schooling'].isna().sum() == 0  #unit test\n",
    "\n",
    "#mean = 22\n",
    "#median = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#press B to quickly get new cell\n",
    "#press D D to quickly delete cell\n",
    "#press M to change to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['life-exp', 'income', 'schooling']\n",
    "\n",
    "# for col in cols:\n",
    "#     df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# assert df['life-exp'].isna().sum() == 0\n",
    "# assert df['income'].isna().sum() == 0\n",
    "# assert df['schooling'].isna().sum() == 0\n",
    "\n",
    "#one thing very important\n",
    "#if YOU HAVE MISSING VALUES, when you run ML models\n",
    "#   you will get error:  Infinity NaN values.....\n",
    "#if you want to drop the rows, use df[colname].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Convert strings to numbers (float/int)\n",
    "\n",
    "- because ALL ML and DL models don't take strings\n",
    "  - data type error:  Expected int/float but got strings\n",
    "- to quickly scan use info(), note the \"objects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info() \n",
    "#scan for dtype = objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory/principle how to convert string to integer/float\n",
    "\n",
    "Three ways:\n",
    "\n",
    "1. **Label encoding**: Just change to number:\n",
    "   1. Example: change developing to 0, developed to 1\n",
    "   2. Pros: super simple\n",
    "   3. Cons: imagine you got encoded 0, 1, 2, 3, 4, 5\n",
    "      1. You create a unwanted knowledge of order within this, e.g., 5 > 1\n",
    "      2. NEVER USE label encoding if you have more than two categories\n",
    "2. **One-hot encoding**: Pivot the values and make it become the columns\n",
    "   1. Delete the column \"Status\"\n",
    "   2. Put Developing as one column; Developed as another column\n",
    "      1. if Developing is true, put 1, and then Developed will be 0\n",
    "      2. if Developing is false, put 0, and then in the Developed col, will be 1\n",
    "3. **Sparse one-hot encoding**: if you have n columns of pivot, you can always delete 1 to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nle.fit_transform(some_make_up_data) \\n\\n=== \\n\\nle.fit(some_make_up_data)  #learn the mapping\\nresult = le.transform(some_make_up_data)  #transform the data\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to convert Status to 0 and 1\n",
    "#easiest way is to use sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#1. import the library\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#2. create the object\n",
    "le = LabelEncoder()\n",
    "\n",
    "#3. fit and transform\n",
    "some_make_up_data = np.array([\"Male\", \"Female\", \"Female\", \"Male\"]) #===one column of df\n",
    "result = le.fit_transform(some_make_up_data)\n",
    "\n",
    "print(result)\n",
    "\n",
    "#if you want to know which map to which, use le.inverse_transform(np.array([0, 1]))\n",
    "\n",
    "'''\n",
    "le.fit_transform(some_make_up_data) \n",
    "\n",
    "=== \n",
    "\n",
    "le.fit(some_make_up_data)  #learn the mapping\n",
    "result = le.transform(some_make_up_data)  #transform the data\n",
    "\n",
    "'''\n",
    "\n",
    "#i want to tell the difference between fit and transform\n",
    "#fit means learn the pattern\n",
    "#transform means transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise: please tranform Status using LabelEncoder\n",
    "df['status_en'] = le.fit_transform(df['Status'])\n",
    "df['status_en'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Developed', 'Developing'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to know that what maps to what \n",
    "le.inverse_transform(np.array([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test that my transformation is correct\n",
    "assert len(df['status_en'].unique()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break: 16:50 - 17:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Standardization / Normalization\n",
    "\n",
    "-i.e., we usually do splitting before any preprocessing\n",
    "\n",
    "- splitting - test train split before any preprocessing\n",
    "  - if you standardize\n",
    "  - if you fill missing value with some global statistics, you should split\n",
    "  - (it's ok to label encode)\n",
    "\n",
    "- when some knowledge of the testing set flows to the training set, we called \"data leakage\"  --> this is one of MOST COMMON MISTAKES of all beginners...like 99%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 5], [2, 6], [3, 7], [4, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3, 4]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2 - 2.5) / 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each feature, do (x - mean) / std\n",
    "\n",
    "#for the first feature, mean = (1 + 2 + 3 + 4) / 4 = 2.5\n",
    "# for the first data, do (1 - 2.5) / 1.11 = -1.35\n",
    "# for the second data, do (2 - 2.5) / 1.11 = -0.45\n",
    "\n",
    "#after standardization, all features will have same scale\n",
    "#all features mean = 0, std = 1\n",
    "\n",
    "#1. import the library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#2. create the object\n",
    "sc = StandardScaler()\n",
    "\n",
    "#3. fit and transform\n",
    "standardized_data = sc.fit_transform(data)\n",
    "\n",
    "print(standardized_data)\n",
    "\n",
    "#when do you want to standardize your data:\n",
    "#1. when you use regression, definitely yes - feature importance\n",
    "#2. in most classification algorithms (not distance-based algorithms), you benefit a bit\n",
    "#   from standardization\n",
    "#3. your training will be more stable\n",
    "\n",
    "#when you should NOT standardize your data:\n",
    "#1. when the mean does not represent well your data\n",
    "#   signal\n",
    "#   we can either do nothing or do min-max normalization\n",
    "#from sklearn.preprocessing import MinMaxScaler #try this at your home\n",
    "# (x - xmax) / (xmax - xmin) ==> (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Extracton / Selection\n",
    "\n",
    "- Seriously consider which X and y to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['income', 'schooling', 'status_en']]\n",
    "X.shape\n",
    "\n",
    "#for X to be used with sklearn, it must be in the shape of (m, n)\n",
    "#where m is number of samples, and n is number of features\n",
    "#if you have only one feature, n = 1 (e.g., it cannot be (m, ); MUST be (m, 1))\n",
    "\n",
    "assert X.shape[0] > 0\n",
    "assert X.shape[1] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['life-exp']\n",
    "#for y to be used with sklearn, if you only have one label,\n",
    "#the shape is (m, ), where m is number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test-train-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2056, 3), (882, 3), (2056,), (882,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "assert int(X.shape[0] * 0.7) == X_train.shape[0]\n",
    "assert int(X.shape[0] * 0.7) == y_train.shape[0]\n",
    "assert int(math.ceil(X.shape[0] * 0.3)) == X_test.shape[0]\n",
    "assert int(math.ceil(X.shape[0] * 0.3)) == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fillna\n",
    "\n",
    "- I assume you already deleted fillna on top!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before income:  0.678\n",
      "Before schooling:  12.3\n",
      "After income:  0.678\n",
      "After schooling:  12.3\n",
      "Before income test set:  0.677\n",
      "Before schooling test set:  12.4\n",
      "After income test set:  0.678\n",
      "After schooling test set:  12.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-1b7b48c49471>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['income'].fillna(X_train['income'].median(), inplace=True)\n",
      "<ipython-input-23-1b7b48c49471>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['schooling'].fillna(X_train['schooling'].median(), inplace=True)\n",
      "<ipython-input-23-1b7b48c49471>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['income'].fillna(X_train['income'].median(), inplace=True)\n",
      "<ipython-input-23-1b7b48c49471>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['schooling'].fillna(X_train['schooling'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before income: \", X_train['income'].median())\n",
    "print(\"Before schooling: \", X_train['schooling'].median())\n",
    "\n",
    "X_train['income'].fillna(X_train['income'].median(), inplace=True)\n",
    "X_train['schooling'].fillna(X_train['schooling'].median(), inplace=True)\n",
    "\n",
    "print(\"After income: \", X_train['income'].median())\n",
    "print(\"After schooling: \", X_train['schooling'].median())\n",
    "\n",
    "print(\"Before income test set: \", X_test['income'].median())\n",
    "print(\"Before schooling test set: \", X_test['schooling'].median())\n",
    "\n",
    "#use median of training set to fillna for testing set\n",
    "X_test['income'].fillna(X_train['income'].median(), inplace=True)\n",
    "X_test['schooling'].fillna(X_train['schooling'].median(), inplace=True)\n",
    "\n",
    "print(\"After income test set: \", X_test['income'].median())\n",
    "print(\"After schooling test set: \", X_test['schooling'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train['income'].isna().sum() == 0\n",
    "assert X_train['schooling'].isna().sum() == 0\n",
    "\n",
    "assert X_test['income'].isna().sum() == 0\n",
    "assert X_test['schooling'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i want to show, let's say standardization, how to do\n",
    "\n",
    "#please assume the same for any other preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please assume the same for fillna\n",
    "\n",
    "#Exercise: \n",
    "# i want you to restart this notebook, but now, fillna with median() \n",
    "# from the training set...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_median    = np.median(X_train[: , 0])\n",
    "schooling_median = np.median(X_train[:,  1])\n",
    "\n",
    "income_median, schooling_median\n",
    "\n",
    "#hint: get the median first, before it got standardized, \n",
    "# if not, the value you replaced is not valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2056, 3), (882, 3), (2056,), (882,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999999, 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0].mean(), X_train[:, 1].mean()\n",
    "X_train[:, 0].std(), X_train[:, 1].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest is NOT really Pandas job\n",
    "\n",
    "5. Training \n",
    "   1. cross validaiton, grid search\n",
    "6. Testing / Inference\n",
    "7. Deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
